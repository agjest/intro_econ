---
title: "Om oppgavene 4C1 og 4C3 fra Wooldridge"
output:
  pdf_document: default
  html_document:
    df_print: paged
editor_options: 
  markdown: 
    wrap: sentence
---

```{r setup}
suppressPackageStartupMessages(library(wooldridge))
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(car))
suppressPackageStartupMessages(library(multcomp))
suppressPackageStartupMessages(library(olsrr))
suppressPackageStartupMessages(library(mctest))
suppressPackageStartupMessages(library(lmtest))
```

# Aller først; standard lineær regresjon i R

R bruker en såkalt `formula` for å spesifisere modellen.
Dette innebærer at operasjoner som "+", "-", ":", "\*", "\^" og tom.
"%in" får helt ny betyding (se ?formula for detaljer).
Ønsker vi at de skal ha sin vanlige betydning må vi sette dem inn i en `I()` funksjon (fra help: *Change the class of an object to indicate that it should be treated 'as is'.)*.
Funksjoner kan vi fritt bruke inne i en formula så vi kan gjerne ha `log(price)` som en variabel.
Det er altså ingen grunn til først å lage en ny variabel `lprice = log(price)`.

For å vise hvordan en enkel multippel regresjon kan formuleres og tolkes i R kan vi ta utgangspunkt i eksempel 3.5 Wooldridge.
Pakken `wooldridge` er lastet så vi trenger bare

```{r}
data(crime1)
```

for å få tilgang til datasettet `crime1`.
Sjekker vi klassen til crime1 vha.
\``` class(crime1)` `` får vi til svar: `r class(crime1)`.
Dataene er altså klar til bruk.

```{r}
# spesifiserer modellen, _mr for multippel regresjon
mod_mr = "narr86 ~ pcnv + ptime86 + qemp86"
lm_mr <- lm(mod_mr, data=crime1)
```

For å se rapporten fra regresjonen kan vi skrive:

```{r}
summary(lm_mr)
```

Her er da en standard rapport fra en regresjon, med estimerte koeffisienter, standard-feil og t-verdier for å teste om koeffisientene er forskjellig fra 0.

Vi ser at alle koeffisientene er klart signifikant forskjellige fra null.
Fortegnene er også som forventet

-   Datasettet inneholder informasjon om menn fra California født 1960 eller 1961 som har vært arrestert *minst* en gang i årene før 1986.
-   narr86: antall ganger en person ble arrestert i 1986
-   pcnv: andel av arresterte før 1986 som ble dømt. Koeffisienten ha verdien -0,1499, dvs alt annet like vil høyere andel dømt føre til færre arrestasjoner 1986.
-   avgsen: gjennomsnittlig straff sonet for tidligere forhold
-   ptime86: antall måneder sonet i fengsel i 1986. Koeffisienten har verdien -0,0344, dvs. dess mer tid i fengsel 1986 dess færre arrestasjoner (vanskelig å bli arrestert hvis du alt soner)
-   qemp86: muligheter for å få jobb 1986. Koeffisienten er -0,1041, dvs. dess bedre jobbmarkedet er dess færre arrestasjoner.

Ønsker vi mer diagnostikk for modellen kan vi

```{r}
plot(lm_mr)
```

Så utvider vi modellen med å ta med variabelen `avgsen`.
Dette gir oss

```{r}
mod_mr_2 = "narr86 ~ pcnv + avgsen + ptime86 + qemp86"
lm_mr_2 <- lm(mod_mr_2, data=crime1)
```

```{r}
summary(lm_mr_2)
```

Ser at variabelen `avgsen` bare gir en liten økning i R-squared, koeffisienten er ikke signifikant og fortegnet er motsatt av forventet.
Positivt fortegn, dvs at lengre straffer skulle medføre flere arrestasjoner.
Taler for at `avgsen` kanskje ikke er en god forklaringsvariabel.

Ønsker vi å sjekke om residualene er normalfordelt kan vi grafisk utforske dette vha.

```{r}
data.frame(res=residuals(lm_mr_2)) %>% 
  ggplot(mapping=aes(x=res)) +
  geom_histogram(binwidth = .25)
```

Ser ikke så bra ut.
Kanskje vi skal prøve med å log-transformere avhengig variabel.
Sjekker først variabelen vha.
summary

```{r}
summary(crime1$narr86)
```

Ser at vi har mange verdier lik 0, går ikke bra med ln.
Et «triks» som ofte blir brukt er å legge til en liten positiv verdi, f.eks 0.01.
Vi må huske at bruker vi «+» så må denne beskyttes av I() i en formula.

```{r}
mod_mr_2_log = "log(I(narr86 + 0.01)) ~ pcnv + avgsen + ptime86 + qemp86"
lm_mr_2_log <- lm(mod_mr_2_log, data=crime1)
```

```{r}
summary(lm_mr_2_log)
```

Vi ser at log-transformasjonen av den avhengige variabelen øker $R^2$ .
Variabelen `avgsen` er fremdeles ikke signifikant og har motsatt fortegn fra forventet.

Sjekker residualene på ny

```{r}
data.frame(res = as.numeric(residuals(lm_mr_2_log))) %>% 
  ggplot(mapping=aes(x = res)) +
  geom_histogram(binwidth = .05)
```

Kanskje noe bedre, men residualene ser ut til å være langt fra normalfordelt.

Ønsker en å teste nærmere en regresjonsmodell er pakken `olsrr` et flott verktøy.
Pakken har utmerket dokumentasjon (se [intro olsrr](https://cran.uib.no/web/packages/olsrr/vignettes/intro.html "intro olsrr") ) og er laget spesielt mht.
å teste om forutsetningene for en lineær regresjon er brutt.
Vi bruker modellen `lm_mr_2` siden `olsrr` ikke ser ut til å like modeller som inneholder bruk av `I()` funksjonen, dvs.
skulle vi brukt modellen `lm_mr_2_log` måtte vi først laget oss en ny variabel `lnarr86 = log(narr86 + 0.01)`.

```{r}
ols_plot_diagnostics(lm_mr_2)
```

Vi ser klart at det er problemer forbundet med modellen vår.

#### Test for normalitet residualer

```{r}
ols_test_normality(lm_mr_2)
```

Samtlige tester gir at vi kan forkaste null-hypotesen om normalfordelte residualer.

```{r}
ols_plot_resid_qq(lm_mr_2)
```

Hvis residualene skulle være normalfordelt skulle de blå prikkene ligge langs en tilnærmet rett linje.
Vi ser igjen at residualene i regresjonen ikke er normalfordelte.

```{r}
ols_plot_resid_hist(lm_mr_2)
```

Igjen liten støtte for antakelsen om normalfordelte residualer.

#### Test for heteroskedastisitet

En poplær test for heteroskedastisitet er Breusch-Pagan.

```{r}
ols_test_breusch_pagan(lm_mr_2)
```

Vi ser at vi kan forkaste null-hypotesen om konstant varians.

#### Plot av residualer mot modellverdier (fitted values)

Et annet populært diagnose-plot er «Residuals vs Fitted Values».

```{r}
ols_plot_resid_fit(lm_mr_2)
```

Ser ikke bra ut.
Burde ligge som et tilfeldig jevnt bånd langs den horisontale aksen uten noe klarer mønster.

Til sist er det verdt å nevne at `olsrr` også har en informativ regresjon-rapport.

```{r}
ols_regress(lm_mr_2)
```

Vi ser at rapporten bl.a inneholder konfidensintervall for koeffisientene (lower upper).

# Restricted models

Dette er viktig stoff og er dekket i avsnittene 4-2c, 4-4 og 4-5.
Viser først eksemplene fra disse avsnittene løst vha.
R.

# Eksempler løst i R

## Fra avsnitt 4-2c

### **Ex. 4.4**

Modellen

$$
\textsf{log(crime)} = \beta_0 + \beta_1 \textsf{log(enroll)} + u
$$

skriver vi i R som "log(crime) \~ log(enroll)" konstantleddet kommer automatisk.
Skulle vi ønske *uten* konstantledd (generelt frarådet) skriver vi "log(crime) \~ log(enroll) - 1"

```{r mod_cc}
data(campus)
# cc crime campus, finnes også variablene lcrime og lenroll i datasettet der
# ln av variablene alt er tatt. I R er det like lett å bruke funksjonen selv 
mod_cc <- "log(crime) ~ log(enroll)" 
lm_cc <- lm(mod_cc, data=campus)
# uten konstantledd
# mod_cc <- "log(crime) ~ log(enroll) - 1"
```

```{r summary_cc}
summary(lm_cc)
```

Elastisiteten for *`campus crime`* mht.
*`enroll`* (universitetsstørrelse) er altså estimert til $1,2698\approx 1,27$, dvs.
1% økning i antall studenter gir 1,27% økning i kriminalitet.
Et sentralt punkt her er om denne elastisiteten er signifikant større enn 1.
Er den det vil vi ha en *relativ* økning i kriminalitet når størrelsen øker.
Altså at et dobbelt så stort universitet vil ha *mer enn* dobbelt så høy kriminalitet.

Ønsker å test H0: $\beta_1 = 1$ mot H1: $\beta_1 > 1$.
I summary ovenfor er det hypotesene H0: $\beta_1 = 0$ mot H1: $\beta_1 \neq 1$ som blir testet.
Hva gjør vi?
Vi regner ut ny t-verdi vha.
$\frac{\textsf{estimat - verdi i hypotese}}{\textsf{standard error}}$, dvs $\frac{1,2698 - 1}{0,1098}= 2,457$.

Vi må så finne kritisk verdi eller p-verdi (husk ensidig H1 her)

```{r}
# obs. in campus
dim(campus)
num_obs <- dim(campus)[1]
num_obs
```

Antall frihetsgrader (95 DF) kan vi også lese direkte ut fra siste linje i summary ovenfor.

p-verdi (For å se fordelinger kjent av base R kjør `?distributions` i Console)

```{r}
# p-verdi ensidig H1
pt(2.457, df=num_obs-2, lower.tail = FALSE)
```

kritisk verdi, ensidig H1 ulike $\alpha$

```{r alpha5}
# alpha lik 0,05 ensidig
qt(0.05, df = num_obs-2, lower.tail = FALSE)
```

```{r alpha1}
# alpha lik 0,05 ensidig
qt(0.01, df = num_obs-2, lower.tail = FALSE)
```

Vi ser at $\beta_1$ er signifikant forskjellig fra 1 på nivå $\alpha=1\%$, altså har vi en overproporsjonal økning i kriminalitet når universitetsstørrelsen øker.

For ordens skyld: Wooldrige skriver en del om å lage konfidensintervall.
For å finne konfidensintervall for modellen ovenfor gjør vi følgende

```{r}
# default 5% 
confint(lm_cc)
```

```{r}
# 1% 
confint(lm_cc, level=0.99)
```

### Ex. 4.5

```{r}
# Boston housing data; hprice2. See Wooldridge or give command ?hprice2 in console
# for description of the variables
data(hprice2)
mod_hp <- "log(price) ~ log(nox) + log(dist) + rooms + stratio"
lm_hp <- lm(mod_hp, data=hprice2)
```

```{r}
summary(lm_hp)
```

Now $\beta_1$ (coefficient estimate for log(nox) lik -0,9535) er priselastisiteten for boliger mht.
nox utslipp.
Vi ønsker å teste H0: $\beta_1=-1$ mot H1: $\beta_1\neq -1$.
Vi benytter samme teknikk som ovenfor, men husker at nå er alternativ hypotese tosidig.
Vi regner altså ut ny t-verdi vha.
$\frac{\textsf{estimat - verdi i hypotese}}{\textsf{standard error}}$, dvs $\frac{-0,9535 - (-1)}{0,1167}= \frac{0,0465}{0,1167}=0,3985$.
Finner p-verdi og kritiske t-verdier.
Antall frihetsgrader er 501.

```{r}
# p-verdi tosidig H1
2*pt(0.3985, df=501, lower.tail=FALSE)
```

Kritisk t-verdi 5% nivå

```{r}
# alpha lik 0,05 tosidig
qt(0.05/2, df = 501, lower.tail = FALSE)
```

For ordens skyld også

```{r}
# alpha lik 0,05 tosidig
qt(0.05/2, df = 501, lower.tail = TRUE)
```

Vi kan altså ikke forkaste H0, dvs.
det er lite bevis for at $\beta_1$ er forskjellig fra -1.

## Fra avsnitt 4-4

Testing av hypoteser med én lineær kombinasjon av parametre.

Modellen

$$
\textsf{log(wage)} = \beta_0 + \beta_1\textsf{jc} + \beta_2\textsf{univ} + \beta_3\textsf{exper} + u
$$

```{r}
data(twoyear)
#variable lwage in dataset is log(wage)
mod_2y <- "lwage ~ jc + univ +exper"
lm_2y <- lm(mod_2y, data = twoyear)
```

```{r}
summary(lm_2y)
```

Vi ser at det lønner seg både med junior college (jc) og college (univ), begge koeffisientene er signifikant forskjellig fra 0.
Det vi er mest interessert i er om $\beta_{\textsf{univ}}$ er *signifikant* større enn $\beta_{\textsf{jc}}$.
Altså om det *lønner seg* å velge universitet fremfor junior college.

For å test trenger vi å beregne t-verdien $t=\frac{\hat{\beta}_1 - \hat{\beta}_2}{\textsf{se}(\hat{\beta}_1 - \hat{\beta}_2)}$.
Problemet er at vi *ikke* finner $\textsf{se}(\hat{\beta}_1 - \hat{\beta}_2)$ i standard rapporten for regresjon.

**NB!** $\textsf{se}(\hat{\beta}_1 - \hat{\beta}_2)\neq \textsf{se}(\hat{\beta}_1) - \textsf{se}(\hat{\beta}_2)$

Vi bruker derfor et «triks» der vi skriver om modellen slik at $\textsf{se}(\hat{\beta}_1 - \hat{\beta}_2)$ vil bli rapportert i standard `summary` fra modellen.

Definerer en ny parameter $\theta_1=\beta_1-\beta_2$ som gir at $\beta_1 = \theta_1 + \beta_2$.
Det vi ønsker å teste er H0: $\theta=0$ mot H1: $\theta<0$.
Vi er nå på jakt etter $\textsf{se}(\theta_1)$ som vil være lik $\textsf{se}(\hat{\beta}_1 - \hat{\beta}_2)$.
Vi kan da skrive om modellen som

$$
\textsf{log(wage)} = \beta_0 + \beta_1\textsf{jc} + \beta_2\textsf{univ} + \beta_3\textsf{exper} + u = \beta_0 + (\theta_1 + \beta_2)\textsf{jc} + \beta_2\textsf{univ} + \beta_3\textsf{exper} + u 
$$

som gir$$
\textsf{log(wage)}= \beta_0 + \theta_1\textsf{jc} + \beta_2(\textsf{univ} +  \textsf{jc}) + \beta_3\textsf{exper} + u
$$

Vi kan altså få tak i $\textsf{se}(\hat{\beta}_1 - \hat{\beta}_2)$ ved å kjøre modellen

```{r}
# Legg merke til bruk av I() funksjonen. Denne trengs siden + har  en spesiell
# betydning i R sitt formula «språk». Inne i I() blir det summen av univ og jc for
# hver student
mod_2y_b <- "lwage ~ jc + I(univ + jc) + exper"
lm_2y_b <- lm(mod_2y_b, data = twoyear)
```

```{r}
summary(lm_2y_b)
```

Da kan vi lese ut standard error for $\theta_1$, som jo også er standard error for $(\hat{\beta}_1 - \hat{\beta}_2)$ som var det vi var på jakt etter.
Da kan vi enkelt regne ut t-verdien

$$
t=\frac{\hat{\beta}_1 - \hat{\beta}_2}{\textsf{se}(\hat{\beta}_1 - \hat{\beta}_2)} = \frac{-0,01018}{0,00694}\approx -1,467
$$

Finner p-verdi (ensidig)

```{r}
# p-verdi ensidig H1
pt(-1.467, df=6759)
```

Vi kan altså *ikke* på 5% nivå konkludere med at et år utdanning på college gir signifikant høyere lønn enn et år på junior college.
På 10% nivå derimot kan vi konkludere med at ett år på college gir signifikant mer uttelling i lønn enn ett år på junior college.

Teknikken ovenfor kan vi *alltid* få til i et statistikkprogram.
Finnes imidlertid pakker/rutiner som forsøker å forenkle dette.
To slike, *car* og *multcomp* er vist nedenfor.
Begge bruker F-test (istdenfor t-test) som samsvarer mer med avsnitt 4-5, men konklusjonene blir de samme.

#### Med pakken `car`

Enklere måte (bruker F-test jmf. avsnitt 4-5)

```{r}
# vi har lastet car så linearHypothesis er tilgjengelig
linearHypothesis(lm_2y, "jc - univ = 0")
```

```{r}
# pf: p value F distribution
pf(2.154, 1, Inf, lower.tail = FALSE)
```

Som en ser er resultatet ovenfor tosidig H1, ønsker en ensidig H1: $\beta_1 < \beta_2$ blir $p = 0,142199/2\approx 0,071$.

#### Med pakken `multcomp`

Med pakken `multcomp` er det enkelt å formulere ensidige hypoteser også.
Denne er kanskje den enkleste å bruke.

```{r}
library(multcomp)
# Specify the linear hypothesis
glht_mod <- glht(
  model = lm_2y, 
  linfct = c("jc - univ <= 0")
)

# Inspect summary 
summary(glht_mod)
```

$\textsf{Pr}(<t) = 1 - \textsf{Pr}(>t) = 1 - 0,929 = 0,071$

```{r}
# Inspect confidence interval
confint(glht_mod)
```

Vi ser at konfidensintervallet inneholder null så vi kan ikke forkaste at $\beta_1 = \beta_2$, dvs.
vi kan ikke forkaste at jc gir samme uttelling som univ på 5% nivå.

## Gjennomgangseksemplet avsnitt 4-5

Baseball (mlb1).
Vi trenger ikke forstå baseball for å kunne forstå eksemplet.

```{r}
data(mlb1)
mod_bb <- "log(salary) ~ years + gamesyr + bavg + hrunsyr + rbisyr"
lm_bb <- lm(mod_bb, data = mlb1)
```

Historien er da at variablene `bavg, hrunsyr, rbisyr` angir spillernes individuelle ferdigheter.
Spørsmålet er om dette betyr noe for lønn eller om det bare er hvor lenge en har spillet (years) og gjennomsnittlig antall kamper per år en har fått spille (gamesyr) som bestemmer lønnsnivået.

```{r}
summary(lm_bb)
```

Det vi ønsker å teste er om individuelle ferdigheter er overflødig i modellen, dvs om $\beta_3=0$, $\beta_4 = 0$ og $\beta_5 = 0$.

Læreboken gjør dette «manuelt» vha.
SSR fra restricted og unrestricted model.

```{r}
mod_bb_r <- "log(salary) ~ years + gamesyr"
lm_bb_r <- lm(mod_bb_r, data = mlb1)
```

```{r}
summary(lm_bb_r)
```

```{r}
(ssr_u <- sum(residuals(lm_bb)^2))
```

```{r}
(ssr_r <- sum(residuals(lm_bb_r)^2))
```

F verdien blir da (n=353 obs, k =5 og q = 3

```{r}
(F_bb <- (ssr_r -ssr_u)/ssr_u * ((353-5-1)/3))
```

F-verdien kan så sjekkes opp mot tabell eller

```{r}
pf(9.5503, 3, 347, lower.tail = FALSE)
```

Kritisk verdi 1%

```{r}
qf(c(0.005, 0.995), 3, 347)
```

Vi ser at vi kan forkaste hypotesen om at individuelle ferdigheter ikke har betydning for lønnen.

#### Samme med bruk av `linearHypothesis`

```{r}
linearHypothesis(lm_bb, c("bavg = 0", "hrunsyr = 0", "rbisyr = 0"))
```

#### Samme med bruk av `multcomp`

```{r}
# Specify the linear hypothesis
glht_mod <- glht(
  model = lm_bb, 
  linfct = c("bavg + hrunsyr + rbisyr = 0")
)

# Inspect summary 
summary(glht_mod)
```

`multcomp` bruker her en mer avansert simultan test (som jeg ikke tror vi skal bekymre oss om å forstå nå), men konklusjonen blir den samme.

### Ex. 4.9

```{r}
data(bwght)
summary(bwght[,4:7])
```

Vi har 196 NA i `fatheduc` og 1 i `motheduc`.
Vi velger å jobbe med komplette observasjoner.

```{r}
mod_bw <- "bwght ~ cigs + parity + faminc + motheduc +fatheduc"
lm_bw <- lm(mod_bw, data = bwght[complete.cases(bwght),])
```

```{r}
summary(lm_bw)
```

```{r}
linearHypothesis(lm_bw, "motheduc +  fatheduc = 0")
```

Dropper å kjøre den simultane testen fra `multcomp`.

```{r, eval=FALSE}
# Specify the linear hypothesis
glht_mod_bw <- glht(
  model = lm_bw, 
  linfct = c("motheduc +  fatheduc = 0")
)

# Inspect summary 
summary(glht_mod_bw)
```

Mor og fars utdannelse blir ikke-signifikant når variablene `cigs`, `parity` og `faminc` blir inkludert.

# Oppgavene

## Oppgave 4C1

i.  Tolkning $\beta_1$?

    Holder alle andre variabler enn $\textsf{expendA}$ fast.
    Gir oss

    $$
    \Delta \textsf{VoteA} = \beta_1 \textsf{log(expendA)} = \frac{\beta_1}{100}(100 \Delta \textsf{log(expendA))} \approx \frac{\beta_1}{100} \% \Delta \textsf{expendA} 
    $$

    Altså gir $\beta_1$ oss tilnærmet antall prosentpoeng økning i $\textsf{voteA}$ når $\textsf{expendA}$ øker med 1%.
    Altså antall prosentpoeng økning (f.eks fra 12,1% til 12,7%, dvs. 0,6 prosentpoeng økning) når vi øker $\textsf{expendA}$ med 1% (f.eks fra 20 millioner til $20\cdot 1,01 = 20,2$ millioner).

    Eksempeltallene er selvsagt tatt rett ut av løse luften som en illustrasjon.
    Et viktig poeng er at den første størrelsen er *prosentpoeng* mens den andre er en relativ størrelse (*prosentvis endring*).
    Disse to begrepene blandes ofte.

ii. H0: $\beta_1 = -\beta_2$ eller H0: $\beta_1 + \beta_2 = 0$.

iii. Hvis expendA og expendB økes med samme prosentvise størrelse (f.eks fra 10 mill. til 10,5 mill. for A og fra 30 mill. til 31,5 mill. for B) vil As andel av stemmene være uendret?

```{r 41cii}
     # load dataset vote1 from wooldridge package
     data(vote1)
     mod1 <- "voteA ~ log(expendA) + log(expendB) + prtystrA"
     lm1 <- lm(mod1, data=vote1)
```

```{r summary-lm1}
summary(lm1)
```

Vi ser fra summary at de estimerte koeffisientene for `log(expendA)` er 6.08332 og -6.61542 for `log(expendB)`.
En økning på 1% i expendA vil altså gi 6,1/100 = 0,0608 prosentpoeng økning i andelen stemmer for kandidat A.
Likeledes vil 1% økning i expendB, alle andre variabler holdt fast, gi en reduksjon på 6,62/100 = 0,0662 prosentpoeng i kandidat As andel av stemmene.
Vi kan ikke teste hypotesen fra ii) utfra resultatene ovenfor siden vi ikke kjenner $\textsf{se}(\beta_1-\beta_2)$.

iv. For å teste hypotesen fra ii) må vi skrive om modellen med $\theta_1 = \beta_1 + \beta_2$ som gir $\beta_1 = \theta_1 - \beta_2$.
    Vi setter inn i modellen og får

    $$
    \textsf{voteA} = \beta_0 + (\theta_1 - \beta_2) \textsf{log(expendA)} + \beta_2 \textsf{log(expendB)} + \beta_3 \textsf{prtystrA}
    $$

som gir oss

$$
\textsf{voteA} = \beta_0 + \theta_1 \textsf{log(expendA)} + \beta_2 (\textsf{log(expendB) - log(expendA))} + \beta_3 \textsf{prtystrA}
$$

Vi kan nå kjøre en standard regresjon på denne modellen og standard error for koeffisienten til `log(expendA)` vil være $\textsf{se}(\beta_1-\beta_2)$ som vi manglet.

```{r}
# Merk bruk av I() funksjonen. Inne i denne virker +, * etc som
# vanlig og ikke som operasjoner i Rs formula språk
mod2_r <- "voteA ~ log(expendA) + I(log(expendA) - log(expendB)) + prtystrA"
lm2_r <- lm(mod2_r, data=vote1)
```

```{r}
summary(lm2_r)
```

Da får vi at $t=\frac{-0.53210}{0.53309} = -0.9981429$.
Vi kan altså ikke forkaste H0.

Gjøre det samme «automagisk» i R

```{r}
linearHypothesis(lm1, "log(expendA) + log(expendB) = 0")
```

Her altså F-test, mens t-ovenfor.
Merk at $t^2 = F$.
Så $-0.9981429^2 = 0,99629$.

## Oppgave 4C3

i)  

```{r}
mod_hp_1 <- "log(price) ~ sqrft + bdrms"
lm_hp_1 <- lm(mod_hp_1, data = hprice1)
```

```{r}
summary(lm_hp_1)
```

Dette gir oss at $\theta_1 = 150 \beta_1 +\beta_2 = 150 \cdot 0.0003794 + 0.02888 = 0,0858$.
Dvs.
prisen øker med 8,58%.

ii) Vi har $\theta_1 = 150 \beta_1 + \beta_2$ som gir $\beta_2 = \theta_1 - 150 \beta_1$. Setter inn for $\beta_2$ og får

$$
\textsf{log}(price) = \beta_0 + \beta_1 \textsf{sqrft} + (\theta_1 - 150 \beta_1) \textsf{bdrms} + u = \beta_0 + \theta_1 \textsf{bdrms} + \beta_1 (\textsf{sqrft} - 150 \textsf{bdrms}) + u
$$

```{r}
# hprice1
mod_hp <- "log(price) ~ bdrms + I(sqrft - 150 * bdrms)"
lm_hp <- lm(mod_hp, data = hprice1)
```

```{r}
summary(lm_hp)
```

Ser at $\theta_1 = 8.580e-02 = 8.580\cdot 10^{-2} = 0,0858$.

iii) Er nok $\theta_1$ og *ikke* $\theta_2$ som menes. Ser at standard error er $4.321\cdot 10^{-05}$.

Vi gjør det enkelt og finner konfidensintervall vha.
`confint`

```{r}
confint(lm_hp)
```

altså fra 3,258% til 13,902%.
